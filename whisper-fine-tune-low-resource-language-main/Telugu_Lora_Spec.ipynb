{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmXIkXrZjVIK",
        "outputId": "a26db8b1-c25c-4d99-e9c9-abdc515657d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/huggingface/transformers\n",
            "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-v05yj8iq\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-v05yj8iq\n",
            "  Resolved https://github.com/huggingface/transformers to commit f2b59c6173191089dadda197554435ce96ae6c84\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (2.32.3)\n",
            "Collecting tokenizers<0.22,>=0.21 (from transformers==4.52.0.dev0)\n",
            "  Using cached tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.52.0.dev0) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.52.0.dev0) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.52.0.dev0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.52.0.dev0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.52.0.dev0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.52.0.dev0) (2025.4.26)\n",
            "Using cached tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.52.0.dev0-py3-none-any.whl size=11697451 sha256=e15e8c7cd1b3d9840a7b9fa5421b26f99936cb4878b37ea84a127a9d6355ef83\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-cvl7mi9r/wheels/04/a3/f1/b88775f8e1665827525b19ac7590250f1038d947067beba9fb\n",
            "Successfully built transformers\n",
            "Installing collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.20.3\n",
            "    Uninstalling tokenizers-0.20.3:\n",
            "      Successfully uninstalled tokenizers-0.20.3\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.45.2\n",
            "    Uninstalling transformers-4.45.2:\n",
            "      Successfully uninstalled transformers-4.45.2\n",
            "Successfully installed tokenizers-0.21.1 transformers-4.52.0.dev0\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.11.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: numpy>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from librosa) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.15.2)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.13.2)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lazy_loader>=0.1->librosa) (24.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.7)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.4.26)\n",
            "Requirement already satisfied: jiwer in /usr/local/lib/python3.11/dist-packages (3.1.0)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from jiwer) (8.1.8)\n",
            "Requirement already satisfied: rapidfuzz>=3.9.7 in /usr/local/lib/python3.11/dist-packages (from jiwer) (3.13.0)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.29.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.12)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.10.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.10.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.30.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.4)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.11.8)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.0->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.4.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Collecting transformers==4.45.2\n",
            "  Using cached transformers-4.45.2-py3-none-any.whl.metadata (44 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.45.2) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.11/dist-packages (from transformers==4.45.2) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.45.2) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.45.2) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.45.2) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.45.2) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.45.2) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.45.2) (0.5.3)\n",
            "Collecting tokenizers<0.21,>=0.20 (from transformers==4.45.2)\n",
            "  Using cached tokenizers-0.20.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.45.2) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.45.2) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.45.2) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.45.2) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.45.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.45.2) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.45.2) (2025.4.26)\n",
            "Using cached transformers-4.45.2-py3-none-any.whl (9.9 MB)\n",
            "Using cached tokenizers-0.20.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "Installing collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.1\n",
            "    Uninstalling tokenizers-0.21.1:\n",
            "      Successfully uninstalled tokenizers-0.21.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.52.0.dev0\n",
            "    Uninstalling transformers-4.52.0.dev0:\n",
            "      Successfully uninstalled transformers-4.52.0.dev0\n",
            "Successfully installed tokenizers-0.20.3 transformers-4.45.2\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.15.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from peft) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from peft) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from peft) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from peft) (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from peft) (4.45.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from peft) (4.67.1)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from peft) (1.6.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from peft) (0.5.3)\n",
            "Requirement already satisfied: huggingface_hub>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from peft) (0.30.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (2025.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->peft) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.11/dist-packages (from transformers->peft) (0.20.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (2025.4.26)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.71.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.8)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboard) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (5.29.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets>=2.6.1\n",
        "!pip install git+https://github.com/huggingface/transformers\n",
        "!pip install librosa\n",
        "!pip install evaluate>=0.30\n",
        "!pip install jiwer\n",
        "!pip install gradio\n",
        "!pip install -q bitsandbytes datasets accelerate loralib\n",
        "!pip install transformers==4.45.2\n",
        "!pip install peft\n",
        "!pip install matplotlib\n",
        "!pip install tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lE5pgftijVIM"
      },
      "outputs": [],
      "source": [
        "# -------------------Set model properties-----------------------------------\n",
        "model_name_or_path = \"openai/whisper-small\"\n",
        "language = \"telugu\"\n",
        "task = \"transcribe\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQLL67VjjVIN"
      },
      "outputs": [],
      "source": [
        "#---------------------------Load Dataset--------------------------------------\n",
        "from datasets import load_dataset, DatasetDict\n",
        "\n",
        "# Load the full dataset\n",
        "full_train = load_dataset(\"raghavab/telugu-asr-small\", split=\"train\")\n",
        "full_test = load_dataset(\"raghavab/telugu-asr-small\", split=\"test\")\n",
        "\n",
        "\n",
        "\n",
        "# Get dataset sizes\n",
        "train_size = len(full_train)\n",
        "test_size = len(full_test)\n",
        "\n",
        "# Compute the original train-test ratio\n",
        "original_ratio = test_size / train_size\n",
        "\n",
        "# Compute the new test size corresponding to 60% train size\n",
        "new_train_size = int(1 * train_size)\n",
        "new_test_size = int(1 * test_size)\n",
        "\n",
        "train_sample = full_train.shuffle(seed=42).select(range(new_train_size))\n",
        "test_sample = full_test.shuffle(seed=42).select(range(new_test_size))\n",
        "\n",
        "# Create a new dataset dictionary\n",
        "bangla_dataset = DatasetDict({\n",
        "    \"train\": train_sample,\n",
        "    \"test\": test_sample\n",
        "})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYXsVo1UjVIO",
        "outputId": "42ba103f-d9a5-4ca8-cc55-6b3fb8c28e83"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': (3113, 2), 'test': (668, 2)}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "#-----------Check dataset shape----------\n",
        "bangla_dataset.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zq8im5d_jVIO",
        "outputId": "ad956a36-da23-451a-94da-dca47cb44300"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['audio', 'transcript'],\n",
              "        num_rows: 3113\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['audio', 'transcript'],\n",
              "        num_rows: 668\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "#-----------Check dataset structure----------\n",
        "bangla_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_hp-KJVjVIO"
      },
      "outputs": [],
      "source": [
        "from transformers import WhisperFeatureExtractor\n",
        "\n",
        "feature_extractor = WhisperFeatureExtractor.from_pretrained(model_name_or_path,language=language,task=task)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3UgNxIfkjVIP"
      },
      "outputs": [],
      "source": [
        "from transformers import WhisperTokenizer\n",
        "\n",
        "tokenizer = WhisperTokenizer.from_pretrained(model_name_or_path,language=language,task=task)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQzflRtFjVIP"
      },
      "outputs": [],
      "source": [
        "from transformers import WhisperProcessor\n",
        "\n",
        "processor = WhisperProcessor.from_pretrained(model_name_or_path, language=language, task=task)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Md8TirejVIP"
      },
      "outputs": [],
      "source": [
        "from transformers import WhisperForConditionalGeneration\n",
        "\n",
        "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\").to('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3F4sYVZYjVIP",
        "outputId": "7c67f02e-cc74-4100-d3e5-e0d2cf695ac1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'audio': {'path': None, 'array': array([ 0.00039673,  0.00036621,  0.00030518, ..., -0.00012207,\n",
            "       -0.00015259, -0.00021362]), 'sampling_rate': 48000}, 'transcript': 'వేర్లు దుంపలుగా నుండును'}\n"
          ]
        }
      ],
      "source": [
        "#-------------------Check sampling rate before downsampling-----------------\n",
        "print(bangla_dataset[\"train\"][16])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DnafsLhsjVIQ"
      },
      "outputs": [],
      "source": [
        "#--------------------Downsample to 16 KHz--------------------------\n",
        "from datasets import Audio\n",
        "\n",
        "bangla_dataset = bangla_dataset.cast_column(\"audio\", Audio(sampling_rate=16000))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zY7_1wV_jVIQ",
        "outputId": "afccb173-5d12-4e55-cc01-beb322cd600d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'audio': {'path': None, 'array': array([-2.24399584e-04, -3.61349492e-04, -3.22890934e-04, ...,\n",
            "       -7.33510751e-05,  1.43645535e-04,  0.00000000e+00]), 'sampling_rate': 16000}, 'transcript': 'అతన్ని తన సహాయకునిగా పెట్టుకున్నాడు'}\n"
          ]
        }
      ],
      "source": [
        "#-------------------Check sampling rate after downsampling-----------------\n",
        "print(bangla_dataset[\"train\"][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gQEd-uvjVIQ"
      },
      "outputs": [],
      "source": [
        "# #------------------Custom preprocessing function for dataset-----------------------------\n",
        "# def prepare_dataset(batch):\n",
        "#     # load and resample audio data from 48 to 16kHz\n",
        "#     audio = batch[\"audio\"]\n",
        "\n",
        "#     # compute log-Mel input features from input audio array\n",
        "#     batch[\"input_features\"] = feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n",
        "\n",
        "#     # encode target text to label ids\n",
        "#     batch[\"labels\"] = tokenizer(batch[\"transcript\"]).input_ids\n",
        "#     return batch\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#------------------Custom preprocessing function with Spec Augment for dataset-----------------------------\n",
        "import torch\n",
        "import random\n",
        "\n",
        "def apply_spec_augment(mel_spec, time_mask_param=20, freq_mask_param=10, num_time_masks=2, num_freq_masks=2):\n",
        "    \"\"\"Applies SpecAugment on a log-Mel spectrogram.\"\"\"\n",
        "    mel_spec = torch.tensor(mel_spec)  # shape: (80, time)\n",
        "\n",
        "    # Frequency masking\n",
        "    for _ in range(num_freq_masks):\n",
        "        f = random.randint(0, freq_mask_param)\n",
        "        f0 = random.randint(0, mel_spec.shape[0] - f)\n",
        "        mel_spec[f0:f0+f, :] = 0\n",
        "\n",
        "    # Time masking\n",
        "    for _ in range(num_time_masks):\n",
        "        t = random.randint(0, time_mask_param)\n",
        "        t0 = random.randint(0, mel_spec.shape[1] - t)\n",
        "        mel_spec[:, t0:t0+t] = 0\n",
        "\n",
        "    return mel_spec.numpy()\n",
        "\n",
        "def prepare_dataset(batch):\n",
        "    audio = batch[\"audio\"]\n",
        "    input_features = feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n",
        "\n",
        "    # Apply SpecAugment only during training\n",
        "    if \"train\" in batch.get(\"__index_level__\", \"\") or \"train\" in batch.get(\"split\", \"\"):\n",
        "        input_features = apply_spec_augment(input_features)\n",
        "\n",
        "    batch[\"input_features\"] = input_features\n",
        "    batch[\"labels\"] = tokenizer(batch[\"transcript\"]).input_ids\n",
        "    return batch\n"
      ],
      "metadata": {
        "id": "eQmo-nCIJxh0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "6e4bf0cbc19741a0912b8e9192532b0a",
            "97112cc357524370826c07693292eeee",
            "0a1bce2ecb7049138c71aedbb45b696b",
            "acbf7cbb84b445b5a5b9993ed8423180",
            "e8b85869a95d4c9ba8d586574d6877c3",
            "d8b4fc9da7d94fee9c5d5a6a38c07a53",
            "ed4b5bf5f36c4e0d9b0d46e31defd6cc",
            "e88656b3ddbd417eabeab042f2713117",
            "c0db436d4be0466f80dde145c2f4a2ff",
            "3758653501d64b8182ff77d6ae83fd4b",
            "3e473ae76cd24649ab8af49a666fe636",
            "10f2a5f4182e4dfa81056e080fc8f018",
            "a0cadd4b21b049cc8bb3455a07612cbb",
            "600b62683bd54e2d8bb9c92339c8c7a5",
            "92ea32f658454d4b8e826aabbba4b179",
            "3cb697b97f1847b2b626fd78386bd2f9",
            "cff4adcd3f414310a1a85fd48b23db12",
            "fb12b986bcce4b9c9d903c786747164b",
            "9224a10dcac1432aacde0217aaf8dced",
            "fe48a9342be449dcb00adc0799a7b49e",
            "e1db1425bfdb4fd6ab95e849eeebcd7c",
            "4ff8c954e7ad4c1b85ce3e118b073035"
          ]
        },
        "id": "31b72TbxjVIQ",
        "outputId": "845a67af-a5be-46d1-9e97-c707dc71c62d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/3113 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6e4bf0cbc19741a0912b8e9192532b0a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/668 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "10f2a5f4182e4dfa81056e080fc8f018"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#-------------------------Execute preprocessing---------------------------\n",
        "bangla_dataset = bangla_dataset.map(prepare_dataset, remove_columns=bangla_dataset.column_names[\"train\"], num_proc=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDkgAb95_iOP",
        "outputId": "e5cfd3fa-f776-4545-c7f7-d5cf50d2c780"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['input_features', 'labels'],\n",
              "    num_rows: 668\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "#--------------check dataset structure after preprocessing------------\n",
        "bangla_dataset[\"test\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXrOOkrEjVIQ",
        "outputId": "74d66043-f7f8-4a10-d8c0-3f826d63954a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['input_features', 'labels'],\n",
              "    num_rows: 3113\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "#--------------check dataset structure after preprocessing------------\n",
        "bangla_dataset[\"train\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hFCZSnMjVIQ",
        "outputId": "7adb5f05-bf65-49bd-85c7-4f30cc4c61cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|startoftranscript|><|te|><|transcribe|><|notimestamps|>అతన్ని తన సహాయకునిగా పెట్టుకున్నాడు<|endoftext|>\n"
          ]
        }
      ],
      "source": [
        "#-------------------Check first sentence by decoding-----------------------\n",
        "first_label_ids = bangla_dataset[\"train\"][0][\"labels\"]  # Get the first label (token IDs)\n",
        "first_sentence = tokenizer.decode(first_label_ids)  # Decode to text\n",
        "\n",
        "print(first_sentence)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jFdI_aekjVIQ"
      },
      "outputs": [],
      "source": [
        "# -----------------------------Visualization of sentence token sizes vs frequency------------------------\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "list_of_transcription_lengths = []\n",
        "\n",
        "# Extract labels from dataset and compute their lengths\n",
        "for data in bangla_dataset[\"train\"]:\n",
        "    list_of_transcription_lengths.append(len(data[\"labels\"]))\n",
        "\n",
        "# Plot the histogram\n",
        "plt.hist(list_of_transcription_lengths, bins=50)  # Adjust bins for better visualization\n",
        "plt.xlabel(\"Sentence Length (Number of Tokens)\")\n",
        "plt.ylabel(\"Number of Transcripts\")\n",
        "plt.title(\"Distribution of Transcription Lengths\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaxwLX2vjVIR",
        "outputId": "a7e8a32d-79fd-4329-ffd6-4cc87cd0d09d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You have passed task=transcribe, but also have set `forced_decoder_ids` to [[1, None], [2, 50359]] which creates a conflict. `forced_decoder_ids` will be ignored in favor of task=transcribe.\n",
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------7------\n",
            "True : అనగా మన దేశానికి హిందీ అధికార భాష\\n \n",
            "Pred :  अनगा मन देसानके हिंदी अदिखार भाशा\n",
            "\n",
            " \n",
            "-------8------\n",
            "True : ఈ సందర్భంలో ఒక కథ చెప్తాను \n",
            "Pred :  इस अंदर्बम लोग के कत चप्तानु\n",
            "\n",
            " \n",
            "-------9------\n",
            "True : జానకి రచన జి \n",
            "Pred :  जानकी रच्चना जी\n",
            "\n",
            " \n"
          ]
        }
      ],
      "source": [
        "#------------------------------Check true vs prediction on few sentences before fine-tuning------------------\n",
        "import torch\n",
        "\n",
        "for idx in range(7,10):\n",
        "    # Get the tokenized target labels\n",
        "    target_tokenized = bangla_dataset[\"train\"][idx][\"labels\"]\n",
        "\n",
        "    # Decode the true text from tokenized format\n",
        "    target_text = tokenizer.decode(target_tokenized, skip_special_tokens=True)\n",
        "\n",
        "    # Convert input features to tensor and add batch dimension\n",
        "    input_feature = torch.tensor(bangla_dataset[\"train\"][idx][\"input_features\"]).unsqueeze(0)\n",
        "\n",
        "    # Ensure correct data type and move to GPU\n",
        "    input_feature = input_feature.to(dtype=torch.float32, device='cuda')  # Use float16 if needed\n",
        "\n",
        "    with torch.no_grad():\n",
        "        op = model.generate(input_feature, language='telugu', task='transcribe')\n",
        "\n",
        "    # Decode predicted text\n",
        "    text_pred = tokenizer.batch_decode(op, skip_special_tokens=True)[0]\n",
        "\n",
        "    print(f'-------{idx}------')\n",
        "    print(f'True : {target_text} \\nPred : {text_pred}')\n",
        "    print('\\n ')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wg-hLV9MjVIR"
      },
      "outputs": [],
      "source": [
        "#-------------------------------------Define Data Collator to introduce padding-------------------------------\n",
        "import torch\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from typing import Any, Dict, List, Union\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class DataCollatorSpeechSeq2SeqWithPadding:\n",
        "    processor: Any\n",
        "\n",
        "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
        "        # split inputs and labels since they have to be of different lengths and need different padding methods\n",
        "        # first treat the audio inputs by simply returning torch tensors\n",
        "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
        "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
        "\n",
        "        # get the tokenized label sequences\n",
        "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
        "        # pad the labels to max length\n",
        "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
        "\n",
        "        # replace padding with -100 to ignore loss correctly\n",
        "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
        "\n",
        "        # if bos token is appended in previous tokenization step,\n",
        "        # cut bos token here as it's append later anyways\n",
        "        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n",
        "            labels = labels[:, 1:]\n",
        "\n",
        "        batch[\"labels\"] = labels\n",
        "\n",
        "        return batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mrWhUoZfjVIR"
      },
      "outputs": [],
      "source": [
        "#----------------------------Load Data Collator-----------------------------\n",
        "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0u3TCq3zjVIR"
      },
      "outputs": [],
      "source": [
        "#------------------------Define evaluation metric wer------------------------\n",
        "import evaluate\n",
        "wer = evaluate.load(\"wer\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AM5QzNJ236DC"
      },
      "outputs": [],
      "source": [
        "#===================================Custom Evaluation Function for WER Metric with Periodic Plotting===================================\n",
        "import torch\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "import evaluate\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output, display\n",
        "\n",
        "wer = evaluate.load(\"wer\")\n",
        "SAVE_PATH = \"evaluation_progress.pkl\"\n",
        "\n",
        "def save_progress(progress):\n",
        "    with open(SAVE_PATH, \"wb\") as f:\n",
        "        pickle.dump(progress, f)\n",
        "\n",
        "def load_progress():\n",
        "    try:\n",
        "        with open(SAVE_PATH, \"rb\") as f:\n",
        "            return pickle.load(f)\n",
        "    except FileNotFoundError:\n",
        "        return {\"predictions\": [], \"references\": [], \"processed_batches\": 0, \"wer_history\": [], \"batch_history\": []}\n",
        "\n",
        "def plot_wer(batch_history, wer_history):\n",
        "    clear_output(wait=True)\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    plt.plot(batch_history, wer_history, marker='o', label='WER (%)')\n",
        "    plt.xlabel('Batches Processed')\n",
        "    plt.ylabel('WER')\n",
        "    plt.title('Running WER Evaluation')\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    # Set ticks at intervals of 25 starting from 0 to max batch\n",
        "    max_batch = max(batch_history) if batch_history else 0\n",
        "    plt.xticks(np.arange(0, max_batch + 1, 25))\n",
        "    display(plt.gcf())\n",
        "    plt.close()\n",
        "\n",
        "def evaluation(model, resume=False):\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "    test_dataset = bangla_dataset[\"test\"]\n",
        "    test_dataloader = torch.utils.data.DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=8,\n",
        "        shuffle=False,\n",
        "        collate_fn=data_collator\n",
        "    )\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # Load previous progress if resuming\n",
        "    progress = load_progress() if resume else {\"predictions\": [], \"references\": [], \"processed_batches\": 0, \"wer_history\": [], \"batch_history\": []}\n",
        "    predictions, references = progress[\"predictions\"], progress[\"references\"]\n",
        "    start_batch = progress[\"processed_batches\"]\n",
        "    wer_history = progress.get(\"wer_history\", [])\n",
        "    batch_history = progress.get(\"batch_history\", [])\n",
        "\n",
        "    for batch_idx, batch in enumerate(tqdm(test_dataloader, total=len(test_dataloader))):\n",
        "        if batch_idx < start_batch:\n",
        "            continue  # Skip already processed batches\n",
        "\n",
        "        input_features = batch[\"input_features\"].to(device)\n",
        "        labels = batch[\"labels\"]\n",
        "\n",
        "        with torch.no_grad():\n",
        "            generated_tokens = model.generate(input_features=input_features, language='telugu', task='transcribe')\n",
        "\n",
        "        decoded_preds = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
        "        decoded_labels = tokenizer.batch_decode(labels.tolist(), skip_special_tokens=True)\n",
        "\n",
        "        predictions.extend(decoded_preds)\n",
        "        references.extend(decoded_labels)\n",
        "\n",
        "        is_final = (batch_idx == len(test_dataloader) - 1)\n",
        "        if (batch_idx + 1) % 25 == 0 or is_final:\n",
        "            current_wer = wer.compute(predictions=predictions, references=references) * 100\n",
        "            wer_history.append(current_wer)\n",
        "            batch_history.append(batch_idx + 1)\n",
        "            plot_wer(batch_history, wer_history)\n",
        "            save_progress({\n",
        "                \"predictions\": predictions,\n",
        "                \"references\": references,\n",
        "                \"processed_batches\": batch_idx + 1,\n",
        "                \"wer_history\": wer_history,\n",
        "                \"batch_history\": batch_history\n",
        "            })\n",
        "\n",
        "    return wer_history[-1] if wer_history else None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "IH-VfcHCDPew",
        "outputId": "b17ce8b5-8fba-4dfc-83e8-00b57114a4b7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 84/84 [17:13<00:00, 12.30s/it]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "196.25445897740786"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "# Evaluate WER before the training\n",
        "torch.cuda.empty_cache()\n",
        "# evaluation(model)\n",
        "evaluation(model,resume=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7e3KMSsKjVIR"
      },
      "outputs": [],
      "source": [
        "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\").to('cuda')\n",
        "model.config.forced_decoder_ids = None\n",
        "model.config.suppress_tokens = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qWuNw-SjVIS",
        "outputId": "4cf858b2-f104-4cb8-a647-1b30b036985d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 7,077,888 || all params: 248,812,800 || trainable%: 2.8447\n",
            "base_model.model.base_model.model.model.encoder.conv1.weight False\n",
            "base_model.model.base_model.model.model.encoder.conv1.bias False\n",
            "base_model.model.base_model.model.model.encoder.conv2.weight False\n",
            "base_model.model.base_model.model.model.encoder.conv2.bias False\n",
            "base_model.model.base_model.model.model.encoder.embed_positions.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.0.self_attn.k_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.0.self_attn.k_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.0.self_attn.k_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.0.self_attn.v_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.0.self_attn.v_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.0.self_attn.v_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.0.self_attn.v_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.0.self_attn.q_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.0.self_attn.q_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.0.self_attn.q_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.0.self_attn.q_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.0.self_attn.out_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.0.self_attn.out_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.0.self_attn.out_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.0.self_attn.out_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.0.self_attn_layer_norm.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.0.self_attn_layer_norm.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.0.fc1.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.0.fc1.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.0.fc2.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.0.fc2.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.0.final_layer_norm.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.0.final_layer_norm.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.1.self_attn.k_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.1.self_attn.k_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.1.self_attn.k_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.1.self_attn.v_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.1.self_attn.v_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.1.self_attn.v_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.1.self_attn.v_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.1.self_attn.q_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.1.self_attn.q_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.1.self_attn.q_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.1.self_attn.q_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.1.self_attn.out_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.1.self_attn.out_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.1.self_attn.out_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.1.self_attn.out_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.1.self_attn_layer_norm.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.1.self_attn_layer_norm.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.1.fc1.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.1.fc1.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.1.fc2.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.1.fc2.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.1.final_layer_norm.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.1.final_layer_norm.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.2.self_attn.k_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.2.self_attn.k_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.2.self_attn.k_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.2.self_attn.v_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.2.self_attn.v_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.2.self_attn.v_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.2.self_attn.v_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.2.self_attn.q_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.2.self_attn.q_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.2.self_attn.q_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.2.self_attn.q_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.2.self_attn.out_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.2.self_attn.out_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.2.self_attn.out_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.2.self_attn.out_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.2.self_attn_layer_norm.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.2.self_attn_layer_norm.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.2.fc1.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.2.fc1.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.2.fc2.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.2.fc2.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.2.final_layer_norm.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.2.final_layer_norm.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.3.self_attn.k_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.3.self_attn.k_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.3.self_attn.k_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.3.self_attn.v_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.3.self_attn.v_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.3.self_attn.v_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.3.self_attn.v_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.3.self_attn.q_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.3.self_attn.q_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.3.self_attn.q_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.3.self_attn.q_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.3.self_attn.out_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.3.self_attn.out_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.3.self_attn.out_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.3.self_attn.out_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.3.self_attn_layer_norm.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.3.self_attn_layer_norm.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.3.fc1.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.3.fc1.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.3.fc2.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.3.fc2.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.3.final_layer_norm.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.3.final_layer_norm.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.4.self_attn.k_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.4.self_attn.k_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.4.self_attn.k_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.4.self_attn.v_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.4.self_attn.v_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.4.self_attn.v_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.4.self_attn.v_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.4.self_attn.q_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.4.self_attn.q_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.4.self_attn.q_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.4.self_attn.q_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.4.self_attn.out_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.4.self_attn.out_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.4.self_attn.out_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.4.self_attn.out_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.4.self_attn_layer_norm.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.4.self_attn_layer_norm.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.4.fc1.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.4.fc1.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.4.fc2.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.4.fc2.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.4.final_layer_norm.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.4.final_layer_norm.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.5.self_attn.k_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.5.self_attn.k_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.5.self_attn.k_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.5.self_attn.v_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.5.self_attn.v_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.5.self_attn.v_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.5.self_attn.v_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.5.self_attn.q_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.5.self_attn.q_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.5.self_attn.q_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.5.self_attn.q_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.5.self_attn.out_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.5.self_attn.out_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.5.self_attn.out_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.5.self_attn.out_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.5.self_attn_layer_norm.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.5.self_attn_layer_norm.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.5.fc1.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.5.fc1.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.5.fc2.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.5.fc2.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.5.final_layer_norm.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.5.final_layer_norm.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.6.self_attn.k_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.6.self_attn.k_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.6.self_attn.k_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.6.self_attn.v_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.6.self_attn.v_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.6.self_attn.v_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.6.self_attn.v_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.6.self_attn.q_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.6.self_attn.q_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.6.self_attn.q_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.6.self_attn.q_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.6.self_attn.out_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.6.self_attn.out_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.6.self_attn.out_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.6.self_attn.out_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.6.self_attn_layer_norm.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.6.self_attn_layer_norm.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.6.fc1.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.6.fc1.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.6.fc2.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.6.fc2.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.6.final_layer_norm.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.6.final_layer_norm.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.7.self_attn.k_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.7.self_attn.k_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.7.self_attn.k_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.7.self_attn.v_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.7.self_attn.v_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.7.self_attn.v_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.7.self_attn.v_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.7.self_attn.q_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.7.self_attn.q_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.7.self_attn.q_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.7.self_attn.q_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.7.self_attn.out_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.7.self_attn.out_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.7.self_attn.out_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.7.self_attn.out_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.7.self_attn_layer_norm.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.7.self_attn_layer_norm.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.7.fc1.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.7.fc1.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.7.fc2.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.7.fc2.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.7.final_layer_norm.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.7.final_layer_norm.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.8.self_attn.k_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.8.self_attn.k_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.8.self_attn.k_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.8.self_attn.v_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.8.self_attn.v_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.8.self_attn.v_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.8.self_attn.v_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.8.self_attn.q_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.8.self_attn.q_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.8.self_attn.q_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.8.self_attn.q_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.8.self_attn.out_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.8.self_attn.out_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.8.self_attn.out_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.8.self_attn.out_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.8.self_attn_layer_norm.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.8.self_attn_layer_norm.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.8.fc1.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.8.fc1.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.8.fc2.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.8.fc2.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.8.final_layer_norm.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.8.final_layer_norm.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.9.self_attn.k_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.9.self_attn.k_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.9.self_attn.k_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.9.self_attn.v_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.9.self_attn.v_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.9.self_attn.v_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.9.self_attn.v_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.9.self_attn.q_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.9.self_attn.q_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.9.self_attn.q_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.9.self_attn.q_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.9.self_attn.out_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.9.self_attn.out_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.9.self_attn.out_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.9.self_attn.out_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.9.self_attn_layer_norm.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.9.self_attn_layer_norm.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.9.fc1.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.9.fc1.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.9.fc2.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.9.fc2.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.9.final_layer_norm.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.9.final_layer_norm.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.10.self_attn.k_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.10.self_attn.k_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.10.self_attn.k_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.10.self_attn.v_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.10.self_attn.v_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.10.self_attn.v_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.10.self_attn.v_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.10.self_attn.q_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.10.self_attn.q_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.10.self_attn.q_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.10.self_attn.q_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.10.self_attn.out_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.10.self_attn.out_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.10.self_attn.out_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.10.self_attn.out_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.10.self_attn_layer_norm.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.10.self_attn_layer_norm.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.10.fc1.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.10.fc1.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.10.fc2.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.10.fc2.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.10.final_layer_norm.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.10.final_layer_norm.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.11.self_attn.k_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.11.self_attn.k_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.11.self_attn.k_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.11.self_attn.v_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.11.self_attn.v_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.11.self_attn.v_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.11.self_attn.v_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.11.self_attn.q_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.11.self_attn.q_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.11.self_attn.q_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.11.self_attn.q_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.11.self_attn.out_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.11.self_attn.out_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.11.self_attn.out_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.11.self_attn.out_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.encoder.layers.11.self_attn_layer_norm.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.11.self_attn_layer_norm.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.11.fc1.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.11.fc1.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.11.fc2.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.11.fc2.bias False\n",
            "base_model.model.base_model.model.model.encoder.layers.11.final_layer_norm.weight False\n",
            "base_model.model.base_model.model.model.encoder.layers.11.final_layer_norm.bias False\n",
            "base_model.model.base_model.model.model.encoder.layer_norm.weight False\n",
            "base_model.model.base_model.model.model.encoder.layer_norm.bias False\n",
            "base_model.model.base_model.model.model.decoder.embed_tokens.weight False\n",
            "base_model.model.base_model.model.model.decoder.embed_positions.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.0.self_attn.k_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.0.self_attn.k_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.0.self_attn.k_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.0.self_attn.v_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.0.self_attn.v_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.0.self_attn.v_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.0.self_attn.v_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.0.self_attn.q_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.0.self_attn.q_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.0.self_attn.q_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.0.self_attn.q_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.0.self_attn.out_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.0.self_attn.out_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.0.self_attn.out_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.0.self_attn.out_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.0.self_attn_layer_norm.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.0.self_attn_layer_norm.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.0.encoder_attn.k_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.0.encoder_attn.k_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.0.encoder_attn.k_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.0.encoder_attn.v_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.0.encoder_attn.v_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.0.encoder_attn.v_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.0.encoder_attn.v_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.0.encoder_attn.q_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.0.encoder_attn.q_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.0.encoder_attn.q_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.0.encoder_attn.q_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.0.encoder_attn.out_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.0.encoder_attn.out_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.0.encoder_attn.out_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.0.encoder_attn.out_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.0.encoder_attn_layer_norm.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.0.encoder_attn_layer_norm.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.0.fc1.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.0.fc1.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.0.fc2.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.0.fc2.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.0.final_layer_norm.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.0.final_layer_norm.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.1.self_attn.k_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.1.self_attn.k_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.1.self_attn.k_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.1.self_attn.v_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.1.self_attn.v_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.1.self_attn.v_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.1.self_attn.v_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.1.self_attn.q_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.1.self_attn.q_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.1.self_attn.q_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.1.self_attn.q_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.1.self_attn.out_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.1.self_attn.out_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.1.self_attn.out_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.1.self_attn.out_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.1.self_attn_layer_norm.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.1.self_attn_layer_norm.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.1.encoder_attn.k_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.1.encoder_attn.k_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.1.encoder_attn.k_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.1.encoder_attn.v_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.1.encoder_attn.v_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.1.encoder_attn.v_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.1.encoder_attn.v_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.1.encoder_attn.q_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.1.encoder_attn.q_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.1.encoder_attn.q_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.1.encoder_attn.q_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.1.encoder_attn.out_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.1.encoder_attn.out_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.1.encoder_attn.out_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.1.encoder_attn.out_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.1.encoder_attn_layer_norm.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.1.encoder_attn_layer_norm.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.1.fc1.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.1.fc1.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.1.fc2.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.1.fc2.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.1.final_layer_norm.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.1.final_layer_norm.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.2.self_attn.k_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.2.self_attn.k_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.2.self_attn.k_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.2.self_attn.v_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.2.self_attn.v_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.2.self_attn.v_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.2.self_attn.v_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.2.self_attn.q_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.2.self_attn.q_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.2.self_attn.q_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.2.self_attn.q_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.2.self_attn.out_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.2.self_attn.out_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.2.self_attn.out_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.2.self_attn.out_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.2.self_attn_layer_norm.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.2.self_attn_layer_norm.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.2.encoder_attn.k_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.2.encoder_attn.k_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.2.encoder_attn.k_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.2.encoder_attn.v_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.2.encoder_attn.v_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.2.encoder_attn.v_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.2.encoder_attn.v_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.2.encoder_attn.q_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.2.encoder_attn.q_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.2.encoder_attn.q_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.2.encoder_attn.q_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.2.encoder_attn.out_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.2.encoder_attn.out_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.2.encoder_attn.out_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.2.encoder_attn.out_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.2.encoder_attn_layer_norm.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.2.encoder_attn_layer_norm.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.2.fc1.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.2.fc1.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.2.fc2.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.2.fc2.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.2.final_layer_norm.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.2.final_layer_norm.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.3.self_attn.k_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.3.self_attn.k_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.3.self_attn.k_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.3.self_attn.v_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.3.self_attn.v_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.3.self_attn.v_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.3.self_attn.v_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.3.self_attn.q_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.3.self_attn.q_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.3.self_attn.q_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.3.self_attn.q_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.3.self_attn.out_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.3.self_attn.out_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.3.self_attn.out_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.3.self_attn.out_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.3.self_attn_layer_norm.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.3.self_attn_layer_norm.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.3.encoder_attn.k_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.3.encoder_attn.k_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.3.encoder_attn.k_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.3.encoder_attn.v_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.3.encoder_attn.v_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.3.encoder_attn.v_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.3.encoder_attn.v_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.3.encoder_attn.q_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.3.encoder_attn.q_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.3.encoder_attn.q_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.3.encoder_attn.q_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.3.encoder_attn.out_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.3.encoder_attn.out_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.3.encoder_attn.out_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.3.encoder_attn.out_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.3.encoder_attn_layer_norm.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.3.encoder_attn_layer_norm.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.3.fc1.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.3.fc1.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.3.fc2.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.3.fc2.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.3.final_layer_norm.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.3.final_layer_norm.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.4.self_attn.k_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.4.self_attn.k_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.4.self_attn.k_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.4.self_attn.v_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.4.self_attn.v_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.4.self_attn.v_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.4.self_attn.v_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.4.self_attn.q_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.4.self_attn.q_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.4.self_attn.q_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.4.self_attn.q_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.4.self_attn.out_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.4.self_attn.out_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.4.self_attn.out_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.4.self_attn.out_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.4.self_attn_layer_norm.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.4.self_attn_layer_norm.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.4.encoder_attn.k_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.4.encoder_attn.k_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.4.encoder_attn.k_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.4.encoder_attn.v_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.4.encoder_attn.v_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.4.encoder_attn.v_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.4.encoder_attn.v_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.4.encoder_attn.q_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.4.encoder_attn.q_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.4.encoder_attn.q_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.4.encoder_attn.q_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.4.encoder_attn.out_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.4.encoder_attn.out_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.4.encoder_attn.out_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.4.encoder_attn.out_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.4.encoder_attn_layer_norm.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.4.encoder_attn_layer_norm.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.4.fc1.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.4.fc1.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.4.fc2.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.4.fc2.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.4.final_layer_norm.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.4.final_layer_norm.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.5.self_attn.k_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.5.self_attn.k_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.5.self_attn.k_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.5.self_attn.v_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.5.self_attn.v_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.5.self_attn.v_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.5.self_attn.v_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.5.self_attn.q_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.5.self_attn.q_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.5.self_attn.q_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.5.self_attn.q_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.5.self_attn.out_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.5.self_attn.out_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.5.self_attn.out_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.5.self_attn.out_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.5.self_attn_layer_norm.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.5.self_attn_layer_norm.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.5.encoder_attn.k_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.5.encoder_attn.k_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.5.encoder_attn.k_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.5.encoder_attn.v_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.5.encoder_attn.v_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.5.encoder_attn.v_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.5.encoder_attn.v_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.5.encoder_attn.q_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.5.encoder_attn.q_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.5.encoder_attn.q_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.5.encoder_attn.q_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.5.encoder_attn.out_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.5.encoder_attn.out_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.5.encoder_attn.out_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.5.encoder_attn.out_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.5.encoder_attn_layer_norm.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.5.encoder_attn_layer_norm.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.5.fc1.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.5.fc1.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.5.fc2.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.5.fc2.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.5.final_layer_norm.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.5.final_layer_norm.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.6.self_attn.k_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.6.self_attn.k_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.6.self_attn.k_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.6.self_attn.v_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.6.self_attn.v_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.6.self_attn.v_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.6.self_attn.v_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.6.self_attn.q_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.6.self_attn.q_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.6.self_attn.q_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.6.self_attn.q_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.6.self_attn.out_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.6.self_attn.out_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.6.self_attn.out_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.6.self_attn.out_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.6.self_attn_layer_norm.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.6.self_attn_layer_norm.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.6.encoder_attn.k_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.6.encoder_attn.k_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.6.encoder_attn.k_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.6.encoder_attn.v_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.6.encoder_attn.v_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.6.encoder_attn.v_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.6.encoder_attn.v_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.6.encoder_attn.q_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.6.encoder_attn.q_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.6.encoder_attn.q_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.6.encoder_attn.q_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.6.encoder_attn.out_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.6.encoder_attn.out_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.6.encoder_attn.out_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.6.encoder_attn.out_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.6.encoder_attn_layer_norm.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.6.encoder_attn_layer_norm.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.6.fc1.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.6.fc1.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.6.fc2.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.6.fc2.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.6.final_layer_norm.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.6.final_layer_norm.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.7.self_attn.k_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.7.self_attn.k_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.7.self_attn.k_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.7.self_attn.v_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.7.self_attn.v_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.7.self_attn.v_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.7.self_attn.v_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.7.self_attn.q_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.7.self_attn.q_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.7.self_attn.q_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.7.self_attn.q_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.7.self_attn.out_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.7.self_attn.out_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.7.self_attn.out_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.7.self_attn.out_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.7.self_attn_layer_norm.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.7.self_attn_layer_norm.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.7.encoder_attn.k_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.7.encoder_attn.k_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.7.encoder_attn.k_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.7.encoder_attn.v_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.7.encoder_attn.v_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.7.encoder_attn.v_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.7.encoder_attn.v_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.7.encoder_attn.q_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.7.encoder_attn.q_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.7.encoder_attn.q_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.7.encoder_attn.q_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.7.encoder_attn.out_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.7.encoder_attn.out_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.7.encoder_attn.out_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.7.encoder_attn.out_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.7.encoder_attn_layer_norm.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.7.encoder_attn_layer_norm.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.7.fc1.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.7.fc1.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.7.fc2.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.7.fc2.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.7.final_layer_norm.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.7.final_layer_norm.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.8.self_attn.k_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.8.self_attn.k_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.8.self_attn.k_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.8.self_attn.v_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.8.self_attn.v_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.8.self_attn.v_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.8.self_attn.v_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.8.self_attn.q_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.8.self_attn.q_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.8.self_attn.q_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.8.self_attn.q_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.8.self_attn.out_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.8.self_attn.out_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.8.self_attn.out_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.8.self_attn.out_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.8.self_attn_layer_norm.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.8.self_attn_layer_norm.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.8.encoder_attn.k_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.8.encoder_attn.k_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.8.encoder_attn.k_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.8.encoder_attn.v_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.8.encoder_attn.v_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.8.encoder_attn.v_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.8.encoder_attn.v_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.8.encoder_attn.q_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.8.encoder_attn.q_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.8.encoder_attn.q_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.8.encoder_attn.q_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.8.encoder_attn.out_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.8.encoder_attn.out_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.8.encoder_attn.out_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.8.encoder_attn.out_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.8.encoder_attn_layer_norm.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.8.encoder_attn_layer_norm.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.8.fc1.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.8.fc1.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.8.fc2.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.8.fc2.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.8.final_layer_norm.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.8.final_layer_norm.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.9.self_attn.k_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.9.self_attn.k_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.9.self_attn.k_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.9.self_attn.v_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.9.self_attn.v_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.9.self_attn.v_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.9.self_attn.v_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.9.self_attn.q_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.9.self_attn.q_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.9.self_attn.q_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.9.self_attn.q_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.9.self_attn.out_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.9.self_attn.out_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.9.self_attn.out_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.9.self_attn.out_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.9.self_attn_layer_norm.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.9.self_attn_layer_norm.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.9.encoder_attn.k_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.9.encoder_attn.k_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.9.encoder_attn.k_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.9.encoder_attn.v_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.9.encoder_attn.v_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.9.encoder_attn.v_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.9.encoder_attn.v_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.9.encoder_attn.q_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.9.encoder_attn.q_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.9.encoder_attn.q_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.9.encoder_attn.q_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.9.encoder_attn.out_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.9.encoder_attn.out_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.9.encoder_attn.out_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.9.encoder_attn.out_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.9.encoder_attn_layer_norm.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.9.encoder_attn_layer_norm.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.9.fc1.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.9.fc1.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.9.fc2.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.9.fc2.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.9.final_layer_norm.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.9.final_layer_norm.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.10.self_attn.k_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.10.self_attn.k_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.10.self_attn.k_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.10.self_attn.v_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.10.self_attn.v_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.10.self_attn.v_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.10.self_attn.v_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.10.self_attn.q_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.10.self_attn.q_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.10.self_attn.q_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.10.self_attn.q_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.10.self_attn.out_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.10.self_attn.out_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.10.self_attn.out_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.10.self_attn.out_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.10.self_attn_layer_norm.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.10.self_attn_layer_norm.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.10.encoder_attn.k_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.10.encoder_attn.k_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.10.encoder_attn.k_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.10.encoder_attn.v_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.10.encoder_attn.v_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.10.encoder_attn.v_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.10.encoder_attn.v_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.10.encoder_attn.q_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.10.encoder_attn.q_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.10.encoder_attn.q_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.10.encoder_attn.q_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.10.encoder_attn.out_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.10.encoder_attn.out_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.10.encoder_attn.out_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.10.encoder_attn.out_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.10.encoder_attn_layer_norm.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.10.encoder_attn_layer_norm.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.10.fc1.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.10.fc1.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.10.fc2.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.10.fc2.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.10.final_layer_norm.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.10.final_layer_norm.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.11.self_attn.k_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.11.self_attn.k_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.11.self_attn.k_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.11.self_attn.v_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.11.self_attn.v_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.11.self_attn.v_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.11.self_attn.v_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.11.self_attn.q_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.11.self_attn.q_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.11.self_attn.q_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.11.self_attn.q_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.11.self_attn.out_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.11.self_attn.out_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.11.self_attn.out_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.11.self_attn.out_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.11.self_attn_layer_norm.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.11.self_attn_layer_norm.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.11.encoder_attn.k_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.11.encoder_attn.k_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.11.encoder_attn.k_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.11.encoder_attn.v_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.11.encoder_attn.v_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.11.encoder_attn.v_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.11.encoder_attn.v_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.11.encoder_attn.q_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.11.encoder_attn.q_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.11.encoder_attn.q_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.11.encoder_attn.q_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.11.encoder_attn.out_proj.base_layer.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.11.encoder_attn.out_proj.base_layer.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.11.encoder_attn.out_proj.lora_A.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.11.encoder_attn.out_proj.lora_B.default.weight True\n",
            "base_model.model.base_model.model.model.decoder.layers.11.encoder_attn_layer_norm.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.11.encoder_attn_layer_norm.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.11.fc1.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.11.fc1.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.11.fc2.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.11.fc2.bias False\n",
            "base_model.model.base_model.model.model.decoder.layers.11.final_layer_norm.weight False\n",
            "base_model.model.base_model.model.model.decoder.layers.11.final_layer_norm.bias False\n",
            "base_model.model.base_model.model.model.decoder.layer_norm.weight False\n",
            "base_model.model.base_model.model.model.decoder.layer_norm.bias False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/peft/mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "#-----------------------------------Load and add LoRA model to base model-----------------------------------\n",
        "from peft import LoraConfig, PeftModel, LoraModel, LoraConfig, get_peft_model\n",
        "\n",
        "config = LoraConfig(r=32, lora_alpha=64, target_modules=[\"k_proj\", \"v_proj\", \"q_proj\", \"out_proj\"], lora_dropout=0.05, bias=\"none\")\n",
        "\n",
        "model = get_peft_model(model, config)\n",
        "model.print_trainable_parameters()\n",
        "for n,p in model.named_parameters():\n",
        "    print(n,p.requires_grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H91bOcsojVIS",
        "outputId": "ff1cb3c5-de11-4f4b-ae65-3d28303cab20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "#----------------------------Create Training Arguments------------------------------\n",
        "from transformers import Seq2SeqTrainingArguments,EarlyStoppingCallback\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"lora-checkpoints\",\n",
        "    per_device_train_batch_size=2,  # Reduced from 8 to 2\n",
        "    per_device_eval_batch_size=2,  # Reduced from 8 to 2\n",
        "    gradient_accumulation_steps=2,  # Helps with small batch size\n",
        "    # learning_rate=2e-5, (High)\n",
        "    learning_rate=1e-5,  #(Medium)\n",
        "    # learning_rate=5e-6,  #(Low)\n",
        "    warmup_steps=50,\n",
        "    num_train_epochs=2,\n",
        "    # evaluation_strategy=\"epoch\",\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=250,\n",
        "    # save_strategy=\"epoch\",\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=500,\n",
        "    save_total_limit=2,\n",
        "    load_best_model_at_end=True,  # Disabling to save memory\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        "    greater_is_better=False,\n",
        "    fp16=True,  # Mixed precision enabled\n",
        "    generation_max_length=128,\n",
        "    logging_steps=25,\n",
        "    remove_unused_columns=False,\n",
        "    label_names=[\"labels\"],\n",
        "\n",
        "    # Add AdamW optimizer and related arguments\n",
        "    optim=\"adamw_torch\",  # AdamW optimizer from PyTorch\n",
        "    weight_decay=0.01,  # Regularization to prevent overfitting\n",
        "    adam_epsilon=1e-8,   # Epsilon for numerical stability\n",
        "    max_grad_norm=1.0,   # Gradient clipping\n",
        "    # TensorBoard logging\n",
        "    logging_dir=\"./lora-tensorboard\",  # Directory for TensorBoard logs\n",
        "    report_to=\"tensorboard\",  # Enables logging to TensorBoard\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yrnekL5FjVIS"
      },
      "outputs": [],
      "source": [
        "#--------------------------------Create Trainer--------------------------------------\n",
        "from transformers import Seq2SeqTrainer\n",
        "\n",
        "# Use only 10% of the test dataset for evaluation\n",
        "# eval_sample = bangla_dataset[\"test\"].shuffle(seed=42).select(range(int(0.1 * len(bangla_dataset[\"test\"]))))\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    args=training_args,\n",
        "    model=model,\n",
        "    train_dataset=bangla_dataset[\"train\"],\n",
        "    eval_dataset=bangla_dataset[\"test\"],\n",
        "    data_collator=data_collator,\n",
        "    #compute_metrics=compute_metrics,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n",
        "model.gradient_checkpointing_enable() #Gradient checkpointing helps save memory by recomputing activations during the backward pass."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Efao7cUaBExs",
        "outputId": "3cae8d8c-1f0a-4007-967c-71f6967062fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ GPU memory forcibly cleared!\n"
          ]
        }
      ],
      "source": [
        "#-------------------Code for Cleaning GPU Cache--------------------------\n",
        "# import torch\n",
        "# import gc\n",
        "\n",
        "# gc.collect()  # Clean up RAM\n",
        "# torch.cuda.empty_cache()  # Free GPU memory\n",
        "\n",
        "# print(\"✅ GPU memory forcibly cleared!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZATCxvLDogTK",
        "outputId": "25532385-eefb-40a8-b6ea-328db7e7c17f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total 4.0K\n",
            "drwxr-xr-x 3 root root 4.0K Mar 17 21:31 imonghose___bengali-asr-data\n",
            "-rw-r--r-- 1 root root    0 Mar 17 21:36 _root_.cache_huggingface_datasets_imonghose___bengali-asr-data_default_0.0.0_3a297ddede51b3012d3a6eb39e9dbea12b8ccc40.lock\n"
          ]
        }
      ],
      "source": [
        "#----------------Code to check stored huggingface dataset files in cache---------------\n",
        "# !ls -lh ~/.cache/huggingface/datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "1304f26a113a4a60a0e66644faee9489",
            "8c4ff2ef4bf84e6ba38eb75cfd3efcb6",
            "591ad8c308704afba5ea324be6407864",
            "28266c528b1a4778972eba45206afa0e",
            "1ea49d94915c46c0a3530d74143c4ae7",
            "4a52def42af84f21b2fe788bd7b331ea",
            "d93084ff9daf4600bd6e6d07c893d0de",
            "478a5b75b79d41e5877c56a0d62d5997",
            "1e6528d9692c4bc295de3c3b3628871d",
            "17cd2149fd0a4d8483c38ceb5ef69d76",
            "0da0390a3c884bfeb87fa82f6ab9dda6",
            "4e67614035e64c22afd3bd02aaf35682",
            "637021f275e94a79a114d03af8b4cf3c",
            "33cc5ea00d0a4150a0d218aed0d8d4ce",
            "73d41185e96c46dbab527ce8bd59d3a0",
            "dc2eec67632b4ddab3e723c523670f8e",
            "0a173b67ee3d4ea0affbb8cd1e359380",
            "7e4188f8b7594ca8aefc832764db6b9c",
            "45fc216c0bea4c7d9d4fdf3d17cacc31",
            "8214bc8eec554073bb8a993f783ac656"
          ]
        },
        "id": "tGPUlQ2hK0Ts",
        "outputId": "35de5a78-9f26-4601-faa9-70acaf36bcb8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1304f26a113a4a60a0e66644faee9489"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#--------------------Login to Huggingface (if required)-----------------------------------\n",
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tSHBSMaNMiAD"
      },
      "outputs": [],
      "source": [
        "#-------------------Check if a checkpoint file exists-----------------------\n",
        "# ls -lh checkpoints/checkpoint-1197\n",
        "# checkpoint_path = get_last_checkpoint(\"checkpoints\")\n",
        "# checkpoint_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IfW2Dm9y36DE"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "fFRb_pHNLWX7",
        "outputId": "3809af66-9df9-4ecc-b28f-dc8609cddbc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No checkpoint found, starting from scratch.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1556' max='1556' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1556/1556 30:51, Epoch 1/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>1.652000</td>\n",
              "      <td>1.611112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.315900</td>\n",
              "      <td>1.294996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>1.097200</td>\n",
              "      <td>1.078409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.958500</td>\n",
              "      <td>0.960909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>0.887800</td>\n",
              "      <td>0.896468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.837400</td>\n",
              "      <td>0.870869</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "#-------------------------------Start Training with support for checkpointing--------------------------\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoModelForCausalLM, Trainer\n",
        "from transformers.trainer_utils import get_last_checkpoint\n",
        "from transformers import WhisperForConditionalGeneration\n",
        "\n",
        "\n",
        "checkpoint_path = get_last_checkpoint(\"lora-checkpoints\")\n",
        "\n",
        "if checkpoint_path is not None:\n",
        "    print(f\"Resuming training from checkpoint: {checkpoint_path}\")\n",
        "    peft_base_model = get_peft_model(WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\"), config)\n",
        "    loaded_model_from_checkpoint = PeftModel.from_pretrained(peft_base_model, checkpoint_path).to('cuda')\n",
        "    model = loaded_model_from_checkpoint\n",
        "    trainer.model = model  # Load the trained model into the trainer\n",
        "    trainer.train(resume_from_checkpoint=checkpoint_path)  # Resume training\n",
        "else:\n",
        "    print(\"No checkpoint found, starting from scratch.\")\n",
        "    torch.cuda.empty_cache()\n",
        "    trainer.train()  # Start training from scratch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r8cFxp3DnbXY"
      },
      "outputs": [],
      "source": [
        "# --------------------------Save LoRa adaptors to \"trained_model\" directory---------------------------\n",
        "trainer.save_model(\"lora_trained_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "myQkjtxf36DE"
      },
      "outputs": [],
      "source": [
        "import ast\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# === Paths to your log files ===\n",
        "train_log_file = \"LoRA_training_logs.txt\"       # Training loss logs (step-level)\n",
        "eval_log_file = \"LoRA_evaluation_logs.txt\"            # Eval loss logs (epoch-level)\n",
        "\n",
        "# === Read and parse training log ===\n",
        "train_data = []\n",
        "with open(train_log_file, 'r') as f:\n",
        "    for line in f:\n",
        "        if line.strip():\n",
        "            log_entry = ast.literal_eval(line.strip())\n",
        "            train_data.append(log_entry)\n",
        "\n",
        "# Extract training epochs and losses\n",
        "train_epochs = [entry['epoch'] for entry in train_data]\n",
        "train_losses = [entry['loss'] for entry in train_data]\n",
        "\n",
        "# === Read and parse evaluation log ===\n",
        "eval_data = []\n",
        "with open(eval_log_file, 'r') as f:\n",
        "    for line in f:\n",
        "        if line.strip():\n",
        "            log_entry = ast.literal_eval(line.strip())\n",
        "            eval_data.append(log_entry)\n",
        "\n",
        "# Extract evaluation epochs and losses\n",
        "eval_epochs = [entry['epoch'] for entry in eval_data]\n",
        "eval_losses = [entry['eval_loss'] for entry in eval_data]\n",
        "\n",
        "# === Plot both training and evaluation loss curves ===\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Training loss: blue with small circles\n",
        "plt.plot(train_epochs, train_losses, linestyle='-', marker='o', markersize=4, label='Training Loss', color='blue')\n",
        "\n",
        "# Evaluation loss: orange with square markers\n",
        "plt.plot(eval_epochs, eval_losses, linestyle='-', marker='s', markersize=6, label='Evaluation Loss', color='orange')\n",
        "\n",
        "# Labels, title, legend, etc.\n",
        "plt.title(\"Training vs Evaluation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_OiCT9lruWq",
        "outputId": "8e63bd52-daa8-40a0-eb0c-b86dd7cc4474"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 84/84 [01:11<00:00,  1.18it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "196.25445897740786"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "# Evaluate WER after the training\n",
        "torch.cuda.empty_cache()\n",
        "evaluation(trainer.model, resume=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0EEmEw4j36DE",
        "outputId": "147b5f14-6e86-4256-c74e-78236fc220c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "#----------------------------Load LoRA adaptors from \"trained_model\" directory and add it to base model to reload---------------------------\n",
        "from transformers import WhisperForConditionalGeneration\n",
        "from peft import PeftModel\n",
        "import torch\n",
        "\n",
        "# Load base model\n",
        "base_model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")\n",
        "\n",
        "loaded_model = get_peft_model(base_model, config)\n",
        "\n",
        "# Load LoRA adapter\n",
        "loaded_model = PeftModel.from_pretrained(loaded_model, \"lora_trained_model\")\n",
        "\n",
        "# ✅ Move model to GPU\n",
        "loaded_model = loaded_model.to(\"cuda\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kSmtiGy636DE"
      },
      "outputs": [],
      "source": [
        "#-----------------------Alternative : Save full model to disk in \"merged_full_model\" directory---------------------------\n",
        "# merged_full_model = trainer.model.merge_and_unload()  # merges LoRA into base model\n",
        "# merged_full_model.save_pretrained(\"merged_full_model\")  # now contains full model weights\n",
        "\n",
        "#-------------------------------Reload the full model from local \"merged_full_model\" directory------------------------------------\n",
        "# from transformers import WhisperForConditionalGeneration\n",
        "# merged_full_model = WhisperForConditionalGeneration.from_pretrained(\"merged_full_model\")\n",
        "# # ✅ Move model to GPU\n",
        "# merged_full_model = merged_full_model.to(\"cuda\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jzQyyvGFn6hs"
      },
      "outputs": [],
      "source": [
        "#-------------------------------Save the loaded model to hugging face------------------------\n",
        "from transformers import WhisperForConditionalGeneration\n",
        "\n",
        "# Push to Hugging Face Hub\n",
        "loaded_model.push_to_hub(\"raghavab/telugu-asr-small-lora-spec-test\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "102825a0ea204d3b8983f44d4bec0c0c",
            "5483f62215214c60be781d0a7506918e",
            "19a98745257e4597bccce82f2c54b04f",
            "fedca8c5bc1c4290b6a254dbc988e9a3",
            "784268ef9420417fbee17a31734dc6f6",
            "ce50b50e29444db9af1c27e957e43294",
            "1365051cd4f24bfcb9168b4986639d0e",
            "a866244316ca4c7b96dd6487a705574e",
            "f627998af35242e8b563381d3a9a705c",
            "e130a0dd52044bb6b3fd6c907bdecb1f",
            "cd952875c2824739af94ea8aa5fc2cae",
            "a1a135c7725d4992aff1cc9f4cd60f80",
            "32592dca8ab84a89accb82b765a7a41a",
            "16292694c3764060b42a43099e035857",
            "822c1e566e2447ff880921d76ece2315",
            "0ed2ad980ad74158beb679bb3d13110b",
            "e5729b55565b478aab6ba07bec237f9f",
            "9cd4e959ba4840e8ba4faf800e5caaac",
            "aa23d843f13e452c8032480d86400ae4",
            "bb525cb40d3842c98a0e533ff3aaa4e3",
            "b4857268546e424ab09dbb001f946c54",
            "c0dd57f5e86f4d8ebfb2861a12f1210c"
          ]
        },
        "id": "KxYEXlIL36DN",
        "outputId": "699cf7b5-cb3d-40ca-ea1e-1853a550e9f7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "adapter_config.json:   0%|          | 0.00/800 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "102825a0ea204d3b8983f44d4bec0c0c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "adapter_model.safetensors:   0%|          | 0.00/28.4M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a1a135c7725d4992aff1cc9f4cd60f80"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#---------------------------------Reload the model from Hugging Face Hub-----------------------------------\n",
        "# Load base model\n",
        "base_model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")\n",
        "\n",
        "peft_model = get_peft_model(base_model, config)\n",
        "# loaded_model = get_peft_model(loaded_model, \"trained_model\")\n",
        "\n",
        "# Load LoRA adapter\n",
        "final_loaded_model = PeftModel.from_pretrained(peft_model, \"raghavab/telugu-asr-small-lora-test\")\n",
        "\n",
        "# ✅ Move model to GPU\n",
        "final_loaded_model = final_loaded_model.to(\"cuda\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CHOPxlxsKx8",
        "outputId": "bafe24f9-02a5-4f73-aa1a-04a9dee7d752"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------7------\n",
            "True : అనగా మన దేశానికి హిందీ అధికార భాష\\n \n",
            "Pred : అనగం మనదయసానికి మందిగారవాసా\n",
            "\n",
            " \n",
            "-------8------\n",
            "True : ఈ సందర్భంలో ఒక కథ చెప్తాను \n",
            "Pred : ఈ సందరమంలో కక చపటాంతు\n",
            "\n",
            " \n",
            "-------9------\n",
            "True : జానకి రచన జి \n",
            "Pred : జానక్రిచనా చేంగ్ల్ల్\n",
            "\n",
            " \n"
          ]
        }
      ],
      "source": [
        "#------------------------------Check true vs prediction on few sentences after fine-tuning (using trainer.model)------------------\n",
        "import torch\n",
        "\n",
        "for idx in range(7,10):\n",
        "    # Get the tokenized target labels\n",
        "    target_tokenized = bangla_dataset[\"train\"][idx][\"labels\"]\n",
        "\n",
        "    # Decode the true text from tokenized format\n",
        "    target_text = tokenizer.decode(target_tokenized, skip_special_tokens=True)\n",
        "\n",
        "    # Convert input features to tensor and add batch dimension\n",
        "    input_feature = torch.tensor(bangla_dataset[\"train\"][idx][\"input_features\"]).unsqueeze(0)\n",
        "\n",
        "    # Ensure correct data type and move to GPU\n",
        "    input_feature = input_feature.to(dtype=torch.float32, device='cuda')  # Use float16 if needed\n",
        "\n",
        "    with torch.no_grad():\n",
        "        op = trainer.model.generate(input_feature, language='telugu', task='transcribe')\n",
        "\n",
        "    # Decode predicted text\n",
        "    text_pred = tokenizer.batch_decode(op, skip_special_tokens=True)[0]\n",
        "\n",
        "    print(f'-------{idx}------')\n",
        "    print(f'True : {target_text} \\nPred : {text_pred}')\n",
        "    print('\\n ')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sZvazsRu36DN",
        "outputId": "def190d3-9725-4159-dc5c-a96cbec701db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------7------\n",
            "True : అనగా మన దేశానికి హిందీ అధికార భాష\\n \n",
            "Pred :  अनगा मन देसानके हिंदी अदिखार भाशा\n",
            "\n",
            " \n",
            "-------8------\n",
            "True : ఈ సందర్భంలో ఒక కథ చెప్తాను \n",
            "Pred :  इस अंदर्बम लोग के कत चप्तानु\n",
            "\n",
            " \n",
            "-------9------\n",
            "True : జానకి రచన జి \n",
            "Pred :  जानकी रच्चना जी\n",
            "\n",
            " \n"
          ]
        }
      ],
      "source": [
        "#------------------------------Check true vs prediction on few sentences after fine-tuning (using model loaded from local i.e \"trained_model\")------------------\n",
        "import torch\n",
        "\n",
        "for idx in range(7,10):\n",
        "    # Get the tokenized target labels\n",
        "    target_tokenized = bangla_dataset[\"train\"][idx][\"labels\"]\n",
        "\n",
        "    # Decode the true text from tokenized format\n",
        "    target_text = tokenizer.decode(target_tokenized, skip_special_tokens=True)\n",
        "\n",
        "    # Convert input features to tensor and add batch dimension\n",
        "    input_feature = torch.tensor(bangla_dataset[\"train\"][idx][\"input_features\"]).unsqueeze(0)\n",
        "\n",
        "    # Ensure correct data type and move to GPU\n",
        "    input_feature = input_feature.to(dtype=torch.float32, device='cuda')  # Use float16 if needed\n",
        "\n",
        "    with torch.no_grad():\n",
        "        op = loaded_model.generate(input_feature, language='telugu', task='transcribe')\n",
        "\n",
        "    # Decode predicted text\n",
        "    text_pred = tokenizer.batch_decode(op, skip_special_tokens=True)[0]\n",
        "\n",
        "    print(f'-------{idx}------')\n",
        "    print(f'True : {target_text} \\nPred : {text_pred}')\n",
        "    print('\\n ')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KPxRp_CL36DN",
        "outputId": "28f0765c-349d-4140-de9b-0315c68db8c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------7------\n",
            "True : అనగా మన దేశానికి హిందీ అధికార భాష\\n \n",
            "Pred :  अनगा मन देसानके हिंदी अदिखार भाशा\n",
            "\n",
            " \n",
            "-------8------\n",
            "True : ఈ సందర్భంలో ఒక కథ చెప్తాను \n",
            "Pred :  इस अंदर्बम लोग के कत चप्तानु\n",
            "\n",
            " \n",
            "-------9------\n",
            "True : జానకి రచన జి \n",
            "Pred :  जानकी रच्चना जी\n",
            "\n",
            " \n"
          ]
        }
      ],
      "source": [
        "#------------------------------Check true vs prediction on few sentences after fine-tuning (using model loaded from hugging face)------------------\n",
        "import torch\n",
        "\n",
        "for idx in range(7,10):\n",
        "    # Get the tokenized target labels\n",
        "    target_tokenized = bangla_dataset[\"train\"][idx][\"labels\"]\n",
        "\n",
        "    # Decode the true text from tokenized format\n",
        "    target_text = tokenizer.decode(target_tokenized, skip_special_tokens=True)\n",
        "\n",
        "    # Convert input features to tensor and add batch dimension\n",
        "    input_feature = torch.tensor(bangla_dataset[\"train\"][idx][\"input_features\"]).unsqueeze(0)\n",
        "\n",
        "    # Ensure correct data type and move to GPU\n",
        "    input_feature = input_feature.to(dtype=torch.float32, device='cuda')  # Use float16 if needed\n",
        "\n",
        "    with torch.no_grad():\n",
        "        op = final_loaded_model.generate(input_feature, language='telugu', task='transcribe')\n",
        "\n",
        "    # Decode predicted text\n",
        "    text_pred = tokenizer.batch_decode(op, skip_special_tokens=True)[0]\n",
        "\n",
        "    print(f'-------{idx}------')\n",
        "    print(f'True : {target_text} \\nPred : {text_pred}')\n",
        "    print('\\n ')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "whisper-env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1304f26a113a4a60a0e66644faee9489": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_d93084ff9daf4600bd6e6d07c893d0de"
          }
        },
        "8c4ff2ef4bf84e6ba38eb75cfd3efcb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_478a5b75b79d41e5877c56a0d62d5997",
            "placeholder": "​",
            "style": "IPY_MODEL_1e6528d9692c4bc295de3c3b3628871d",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "591ad8c308704afba5ea324be6407864": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_17cd2149fd0a4d8483c38ceb5ef69d76",
            "placeholder": "​",
            "style": "IPY_MODEL_0da0390a3c884bfeb87fa82f6ab9dda6",
            "value": ""
          }
        },
        "28266c528b1a4778972eba45206afa0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_4e67614035e64c22afd3bd02aaf35682",
            "style": "IPY_MODEL_637021f275e94a79a114d03af8b4cf3c",
            "value": true
          }
        },
        "1ea49d94915c46c0a3530d74143c4ae7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_33cc5ea00d0a4150a0d218aed0d8d4ce",
            "style": "IPY_MODEL_73d41185e96c46dbab527ce8bd59d3a0",
            "tooltip": ""
          }
        },
        "4a52def42af84f21b2fe788bd7b331ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc2eec67632b4ddab3e723c523670f8e",
            "placeholder": "​",
            "style": "IPY_MODEL_0a173b67ee3d4ea0affbb8cd1e359380",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "d93084ff9daf4600bd6e6d07c893d0de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "478a5b75b79d41e5877c56a0d62d5997": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e6528d9692c4bc295de3c3b3628871d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "17cd2149fd0a4d8483c38ceb5ef69d76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0da0390a3c884bfeb87fa82f6ab9dda6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e67614035e64c22afd3bd02aaf35682": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "637021f275e94a79a114d03af8b4cf3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "33cc5ea00d0a4150a0d218aed0d8d4ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73d41185e96c46dbab527ce8bd59d3a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "dc2eec67632b4ddab3e723c523670f8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a173b67ee3d4ea0affbb8cd1e359380": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e4188f8b7594ca8aefc832764db6b9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45fc216c0bea4c7d9d4fdf3d17cacc31",
            "placeholder": "​",
            "style": "IPY_MODEL_8214bc8eec554073bb8a993f783ac656",
            "value": "Connecting..."
          }
        },
        "45fc216c0bea4c7d9d4fdf3d17cacc31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8214bc8eec554073bb8a993f783ac656": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "102825a0ea204d3b8983f44d4bec0c0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5483f62215214c60be781d0a7506918e",
              "IPY_MODEL_19a98745257e4597bccce82f2c54b04f",
              "IPY_MODEL_fedca8c5bc1c4290b6a254dbc988e9a3"
            ],
            "layout": "IPY_MODEL_784268ef9420417fbee17a31734dc6f6"
          }
        },
        "5483f62215214c60be781d0a7506918e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce50b50e29444db9af1c27e957e43294",
            "placeholder": "​",
            "style": "IPY_MODEL_1365051cd4f24bfcb9168b4986639d0e",
            "value": "adapter_config.json: 100%"
          }
        },
        "19a98745257e4597bccce82f2c54b04f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a866244316ca4c7b96dd6487a705574e",
            "max": 800,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f627998af35242e8b563381d3a9a705c",
            "value": 800
          }
        },
        "fedca8c5bc1c4290b6a254dbc988e9a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e130a0dd52044bb6b3fd6c907bdecb1f",
            "placeholder": "​",
            "style": "IPY_MODEL_cd952875c2824739af94ea8aa5fc2cae",
            "value": " 800/800 [00:00&lt;00:00, 78.3kB/s]"
          }
        },
        "784268ef9420417fbee17a31734dc6f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce50b50e29444db9af1c27e957e43294": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1365051cd4f24bfcb9168b4986639d0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a866244316ca4c7b96dd6487a705574e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f627998af35242e8b563381d3a9a705c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e130a0dd52044bb6b3fd6c907bdecb1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd952875c2824739af94ea8aa5fc2cae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a1a135c7725d4992aff1cc9f4cd60f80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_32592dca8ab84a89accb82b765a7a41a",
              "IPY_MODEL_16292694c3764060b42a43099e035857",
              "IPY_MODEL_822c1e566e2447ff880921d76ece2315"
            ],
            "layout": "IPY_MODEL_0ed2ad980ad74158beb679bb3d13110b"
          }
        },
        "32592dca8ab84a89accb82b765a7a41a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5729b55565b478aab6ba07bec237f9f",
            "placeholder": "​",
            "style": "IPY_MODEL_9cd4e959ba4840e8ba4faf800e5caaac",
            "value": "adapter_model.safetensors: 100%"
          }
        },
        "16292694c3764060b42a43099e035857": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa23d843f13e452c8032480d86400ae4",
            "max": 28357352,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bb525cb40d3842c98a0e533ff3aaa4e3",
            "value": 28357352
          }
        },
        "822c1e566e2447ff880921d76ece2315": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4857268546e424ab09dbb001f946c54",
            "placeholder": "​",
            "style": "IPY_MODEL_c0dd57f5e86f4d8ebfb2861a12f1210c",
            "value": " 28.4M/28.4M [00:00&lt;00:00, 114MB/s]"
          }
        },
        "0ed2ad980ad74158beb679bb3d13110b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5729b55565b478aab6ba07bec237f9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9cd4e959ba4840e8ba4faf800e5caaac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa23d843f13e452c8032480d86400ae4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb525cb40d3842c98a0e533ff3aaa4e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b4857268546e424ab09dbb001f946c54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0dd57f5e86f4d8ebfb2861a12f1210c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e4bf0cbc19741a0912b8e9192532b0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_97112cc357524370826c07693292eeee",
              "IPY_MODEL_0a1bce2ecb7049138c71aedbb45b696b",
              "IPY_MODEL_acbf7cbb84b445b5a5b9993ed8423180"
            ],
            "layout": "IPY_MODEL_e8b85869a95d4c9ba8d586574d6877c3"
          }
        },
        "97112cc357524370826c07693292eeee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8b4fc9da7d94fee9c5d5a6a38c07a53",
            "placeholder": "​",
            "style": "IPY_MODEL_ed4b5bf5f36c4e0d9b0d46e31defd6cc",
            "value": "Map: 100%"
          }
        },
        "0a1bce2ecb7049138c71aedbb45b696b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e88656b3ddbd417eabeab042f2713117",
            "max": 3113,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c0db436d4be0466f80dde145c2f4a2ff",
            "value": 3113
          }
        },
        "acbf7cbb84b445b5a5b9993ed8423180": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3758653501d64b8182ff77d6ae83fd4b",
            "placeholder": "​",
            "style": "IPY_MODEL_3e473ae76cd24649ab8af49a666fe636",
            "value": " 3113/3113 [00:37&lt;00:00, 46.15 examples/s]"
          }
        },
        "e8b85869a95d4c9ba8d586574d6877c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8b4fc9da7d94fee9c5d5a6a38c07a53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed4b5bf5f36c4e0d9b0d46e31defd6cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e88656b3ddbd417eabeab042f2713117": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0db436d4be0466f80dde145c2f4a2ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3758653501d64b8182ff77d6ae83fd4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e473ae76cd24649ab8af49a666fe636": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "10f2a5f4182e4dfa81056e080fc8f018": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a0cadd4b21b049cc8bb3455a07612cbb",
              "IPY_MODEL_600b62683bd54e2d8bb9c92339c8c7a5",
              "IPY_MODEL_92ea32f658454d4b8e826aabbba4b179"
            ],
            "layout": "IPY_MODEL_3cb697b97f1847b2b626fd78386bd2f9"
          }
        },
        "a0cadd4b21b049cc8bb3455a07612cbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cff4adcd3f414310a1a85fd48b23db12",
            "placeholder": "​",
            "style": "IPY_MODEL_fb12b986bcce4b9c9d903c786747164b",
            "value": "Map: 100%"
          }
        },
        "600b62683bd54e2d8bb9c92339c8c7a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9224a10dcac1432aacde0217aaf8dced",
            "max": 668,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fe48a9342be449dcb00adc0799a7b49e",
            "value": 668
          }
        },
        "92ea32f658454d4b8e826aabbba4b179": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1db1425bfdb4fd6ab95e849eeebcd7c",
            "placeholder": "​",
            "style": "IPY_MODEL_4ff8c954e7ad4c1b85ce3e118b073035",
            "value": " 668/668 [00:07&lt;00:00, 124.20 examples/s]"
          }
        },
        "3cb697b97f1847b2b626fd78386bd2f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cff4adcd3f414310a1a85fd48b23db12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb12b986bcce4b9c9d903c786747164b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9224a10dcac1432aacde0217aaf8dced": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe48a9342be449dcb00adc0799a7b49e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e1db1425bfdb4fd6ab95e849eeebcd7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ff8c954e7ad4c1b85ce3e118b073035": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}